{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with Sklearn\n",
    "\n",
    "Data preprocessing for supervised machine learning\n",
    "\n",
    "**What you'll learn in this course üßêüßê**\n",
    "\n",
    "The example below implements all the necessary steps to train a machine learning model and make predictions on a dataset.\n",
    "\n",
    "Use pandas and the preprocessing module of the scikit-learn library to prepare your data.\n",
    "Use scikit-learn to train a supervised machine learning model and assess its performance.\n",
    "We have a sample dataset of conversions available (has someone purchased a product). The objective is to predict whether a person has made a purchase, based on information about that person: nationality, age, and income level.\n",
    "\n",
    "We will call \"variable to predict\", \"variable to explain\" or \"target\", noted Y, the column corresponding to \"Purchased\" in the dataset\n",
    "The other columns of the dataset, called \"explanatory variables\" and denoted X, will be used to try to predict the value of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "...Done.\n",
      "\n",
      "Number of rows : 12\n",
      "\n",
      "Display of dataset: \n",
      "   id  Country   Age  Salary Purchased useless_col  almost_empty\n",
      "0   0   France  44.0   72000        No     useless           NaN\n",
      "1   1    Spain  27.0   48000       Yes     useless          40.0\n",
      "2   2  Germany  30.0   54000        No     useless           NaN\n",
      "3   3    Spain  38.0   61000        No     useless          20.0\n",
      "4   4  Germany  40.0   69000       Yes     useless           NaN\n",
      "\n",
      "Basics statistics: \n",
      "               id Country        Age        Salary Purchased useless_col  \\\n",
      "count   12.000000      12  11.000000  1.200000e+01        12          12   \n",
      "unique        NaN       3        NaN           NaN         2           1   \n",
      "top           NaN  France        NaN           NaN       Yes     useless   \n",
      "freq          NaN       5        NaN           NaN         7          12   \n",
      "mean     5.500000     NaN  36.909091  8.338958e+07       NaN         NaN   \n",
      "std      3.605551     NaN  19.002392  2.886574e+08       NaN         NaN   \n",
      "min      0.000000     NaN -10.000000  3.200000e+04       NaN         NaN   \n",
      "25%      2.750000     NaN  32.500000  5.350000e+04       NaN         NaN   \n",
      "50%      5.500000     NaN  38.000000  6.400000e+04       NaN         NaN   \n",
      "75%      8.250000     NaN  46.000000  7.375000e+04       NaN         NaN   \n",
      "max     11.000000     NaN  67.000000  1.000000e+09       NaN         NaN   \n",
      "\n",
      "        almost_empty  \n",
      "count       2.000000  \n",
      "unique           NaN  \n",
      "top              NaN  \n",
      "freq             NaN  \n",
      "mean       30.000000  \n",
      "std        14.142136  \n",
      "min        20.000000  \n",
      "25%        25.000000  \n",
      "50%        30.000000  \n",
      "75%        35.000000  \n",
      "max        40.000000  \n",
      "\n",
      "Percentage of missing values: \n",
      "id               0.000000\n",
      "Country          0.000000\n",
      "Age              8.333333\n",
      "Salary           0.000000\n",
      "Purchased        0.000000\n",
      "useless_col      0.000000\n",
      "almost_empty    83.333333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = pd.read_csv(\"Dataset_preprocessing.csv\")\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Basic stats\n",
    "print(\"Number of rows : {}\".format(dataset.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "print(dataset.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = dataset.describe(include='all')\n",
    "print(data_desc)\n",
    "print()\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "print(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping useless columns...\n",
      "...Done.\n",
      "   Country   Age  Salary Purchased\n",
      "0   France  44.0   72000        No\n",
      "1    Spain  27.0   48000       Yes\n",
      "2  Germany  30.0   54000        No\n",
      "3    Spain  38.0   61000        No\n",
      "4  Germany  40.0   69000       Yes\n"
     ]
    }
   ],
   "source": [
    "# Drop useless columns / columns with too many missing values\n",
    "useless_cols = ['id', 'useless_col', 'almost_empty']\n",
    "\n",
    "print(\"Dropping useless columns...\")\n",
    "dataset = dataset.drop(useless_cols, axis=1) # axis = 1 indicates that we are dropping along the column axis\n",
    "# never hesitate to look at a function's documentation using the command name_of_the_function?\n",
    "print(\"...Done.\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping outliers in Age...\n",
      "Done. Number of lines remaining :  11\n",
      "\n",
      "Dropping outliers in Salary...\n",
      "Done. Number of lines remaining :  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>69000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age  Salary Purchased\n",
       "0   France  44.0   72000        No\n",
       "1    Spain  27.0   48000       Yes\n",
       "2  Germany  30.0   54000        No\n",
       "3    Spain  38.0   61000        No\n",
       "4  Germany  40.0   69000       Yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop lines containing outliers (using masks)\n",
    "\n",
    "print('Dropping outliers in Age...')\n",
    "to_keep = (dataset['Age'] > 0) | (dataset['Age'].isnull()) # We want keeping positives values or missings\n",
    "dataset = dataset.loc[to_keep,:] \n",
    "print('Done. Number of lines remaining : ', dataset.shape[0])\n",
    "print()\n",
    "\n",
    "print('Dropping outliers in Salary...')\n",
    "to_keep = dataset['Salary'] < dataset['Salary'].mean() + 2*dataset['Salary'].std()\n",
    "dataset = dataset.loc[to_keep,:]\n",
    "print('Done. Number of lines remaining : ', dataset.shape[0])\n",
    "print()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "   Country   Age  Salary\n",
      "0   France  44.0   72000\n",
      "1    Spain  27.0   48000\n",
      "2  Germany  30.0   54000\n",
      "3    Spain  38.0   61000\n",
      "4  Germany  40.0   69000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "target_name = 'Purchased'\n",
    "\n",
    "print(\"Separating labels from features...\")\n",
    "Y = dataset.loc[:,target_name]\n",
    "X = dataset.loc[:,[c for c in dataset.columns if c!=target_name]] # All columns are kept, except the target\n",
    "print(\"...Done.\")\n",
    "print(Y.head())\n",
    "print()\n",
    "print(X.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[['France' 44.0 72000]\n",
      " ['Spain' 27.0 48000]\n",
      " ['Germany' 30.0 54000]\n",
      " ['Spain' 38.0 61000]\n",
      " ['Germany' 40.0 69000]]\n",
      "\n",
      "['No', 'Yes', 'No', 'No', 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X = X.values\n",
    "Y = Y.tolist()\n",
    "print(\"...Done\")\n",
    "print(X[0:5,:])\n",
    "print()\n",
    "print(Y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First : always divide dataset into train set & test set !!\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# test_size indicates the proportion of rows from X and Y that will go into the test dataset while \n",
    "# maintaining the correspondance between the rows from X and Y \n",
    "\n",
    "# random_state is an argument that can be found in all functions that have a pseudo-random behaviour\n",
    "# if random_state is not stated the function will derive a different random result everytime the cell \n",
    "# runs, if random_state is given a value the results will be the same everytime the cell runs while\n",
    "# each different value of radom_state will derive a specific result\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "[['Germany' 40.0 69000]\n",
      " ['France' 37.0 67000]\n",
      " ['Spain' 27.0 48000]\n",
      " ['Spain' nan 52000]\n",
      " ['France' 48.0 79000]]\n",
      "...Done.\n",
      "[[ 0.27978024  0.58858382  1.          0.        ]\n",
      " [-0.23673712  0.38385901  0.          0.        ]\n",
      " [-1.95846165 -1.56102665  0.          1.        ]\n",
      " [-0.06456467 -1.15157703  0.          1.        ]\n",
      " [ 1.65715986  1.61220785  0.          0.        ]]\n",
      "\n",
      "Performing preprocessings on test set...\n",
      "[['Germany' 30.0 54000]\n",
      " ['Germany' 50.0 83000]]\n",
      "...Done.\n",
      "[[-1.44194429 -0.94685223  1.          0.        ]\n",
      " [ 2.00150476  2.02165746  1.          0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_features = [1,2] # Positions of numeric columns in X_train/X_test\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = [0] # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train[0:5,:])\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5,:])\n",
    "print()\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test[0:5,:])\n",
    "X_test = preprocessor.transform(X_test) # Don't fit again !! The test set is used for validating decisions\n",
    "# we made based on the training set, therefore we can only apply transformations that were parametered using the training set.\n",
    "# Otherwise this creates what is called a leak from the test set which will introduce a bias in all your results.\n",
    "print('...Done.')\n",
    "print(X_test[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels on train set...\n",
      "['Yes', 'Yes', 'Yes', 'No', 'Yes']\n",
      "\n",
      "...Done.\n",
      "[1 1 1 0 1]\n",
      "\n",
      "Encoding labels on test set...\n",
      "['No', 'No']\n",
      "\n",
      "...Done.\n",
      "[0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode target variable Y\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "print(\"Encoding labels on train set...\")\n",
    "print(Y_train[0:5])\n",
    "print()\n",
    "Y_train = labelencoder.fit_transform(Y_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train[0:5])\n",
    "print()\n",
    "\n",
    "print(\"Encoding labels on test set...\")\n",
    "print(Y_test[0:5])\n",
    "print()\n",
    "Y_test = labelencoder.transform(Y_test) # Don't fit again !!\n",
    "print(\"...Done.\")\n",
    "print(Y_test[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = LogisticRegression()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train) # Training is always done on train set !!\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[1 1 1 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = model.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = model.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.75\n",
      "Accuracy on test set :  0.0\n"
     ]
    }
   ],
   "source": [
    "# Print scores\n",
    "print(\"Accuracy on training set : \", accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"Accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
